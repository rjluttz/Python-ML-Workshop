{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h4>READING DATASET</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing pandas for reading the datasets\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading the training dataset with a ';' delimiter\nbdata=pd.read_csv('../input/mlworkshop/bank-full.csv',delimiter=';')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# displaying first 10 observations from the dataset\nbdata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# describing the pandas dataframe bdata\nbdata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting details of no of attributes and observations\nprint('No of observations :',bdata.shape[0])\nprint('No of attributes :',bdata.shape[1])\nprint('No of numerical attributes :',bdata.describe().shape[1])\nprint('No of categorical attributes :',bdata.shape[1]-bdata.describe().shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting list of attributes\nbdata.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>UNDERSTANDING FEATURES OF DATASET</h4>\n\n__default__: has credit in default?\n\n__housing__: has housing loan? \n\n__loan__: has personal loan?\n\n__day__: last contact day of the week\n\n__month__: last contact month of year \n\n__duration__: last contact duration, in seconds \n\n__campaign__: number of contacts performed during this campaign and for this client \n\n__pdays__: number of days that passed by after the client was last contacted from a previous campaign\n\n__previous__: number of contacts performed before this campaign and for this client\n\n__poutcome__: outcome of the previous marketing campaign"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing matplotlib for plotting the graphs\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Outcome variable__"},{"metadata":{"trusted":true},"cell_type":"code","source":"bdata['y'].value_counts().plot(kind='bar')\nplt.title('Subscriptions')\nplt.xlabel('Term Deposit')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We observe that the data is highly imbalanced, however we need a balanced data only for training."},{"metadata":{},"cell_type":"markdown","source":"Since the data preprocessing steps are same for both testing and training dataset, we first perform the data preprocessing and then divide the data into training data and testing data."},{"metadata":{},"cell_type":"markdown","source":"<h4>VISUALIZATION</h4>"},{"metadata":{},"cell_type":"markdown","source":"__Job vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.job,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Job')\nplt.xlabel('Job')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Marital Status vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.marital,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Marital Status')\nplt.xlabel('Marital Status')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Education vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.education,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Education')\nplt.xlabel('Education')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Housing Credit vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.housing,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Housing Credit')\nplt.xlabel('Housing Credit')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Personal loan vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.loan,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Personal Loan')\nplt.xlabel('Personal Loan')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Outcome of Previous Campaign vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.poutcome,bdata.y).plot(kind='bar')\nplt.title('Subscriptions based on Outcome of Previous Campaign')\nplt.xlabel('Outcome of Previous Campaign')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Month vs Subscription__"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.crosstab(bdata.month,bdata.y).plot(kind='bar')\nplt.title('Monthly Subscriptions')\nplt.xlabel('Month')\nplt.ylabel('No of Subscriptions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>DATA PREPROCESSING</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating dummy variables for categorical variables\n\n# creating a list of categorical variables to be transformed into dummy variables\ncategory=['job','marital','education','default','housing','loan','contact',\n          'month','poutcome']\n\n# creating a backup\nbdata_new = bdata\n\n# creating dummy variables and joining it to the training set\nfor c in category:\n    new_column = pd.get_dummies(bdata_new[c], prefix=c)\n    bdata_dummy=bdata_new.join(new_column)\n    bdata_new=bdata_dummy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bdata_new.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# see the dummy setup of one categorical variable\nbdata_new[[col for col in bdata_new if col.startswith('education')]].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop the initial categorical variable\nbdata_final=bdata_new.drop(category,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"bdata_final.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# coding no as '0' and yes as '1'\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nlabels = le.fit_transform(bdata_final['y'])\nbdata_final['y'] = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bdata_final.y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bdata_final.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feature selection to reduce dimensionality\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import MinMaxScaler\n\n# creating dataframe of features\nX=bdata_final.drop(['y'],axis=1)\n# creating dataframe of output variable\ny=bdata_final['y']\n\n# standard scaling\nX_norm = MinMaxScaler().fit_transform(X)\n\nrfe_selector = RFE(estimator=LogisticRegression(solver='liblinear',max_iter=100,multi_class='ovr',n_jobs=1), n_features_to_select=30, step=10, verbose=5)\nrfe_selector.fit(X_norm, y)\nrfe_support = rfe_selector.get_support()\nrfe_feature = X.loc[:,rfe_support].columns.tolist()\nprint(str(len(rfe_feature)), 'selected features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfe_feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>features to be eliminated : age, pdays (30 selected features)</p>\n<p>features that may be eliminated : job, marital, education, loan (20 selected features)</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping age and pdays\nbdata_final=bdata_final.drop(['age','pdays'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bdata_final.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat=[col for col in bdata_final if col.startswith('job')]\nmar_cat=[col for col in bdata_final if col.startswith('marital')]\nedu_cat=[col for col in bdata_final if col.startswith('education')]\nloan_cat=[col for col in bdata_final if col.startswith('loan')]\ncat.extend(mar_cat)\ncat.extend(edu_cat)\ncat.extend(loan_cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a dataframe with lesser dimension\nbdata_dr=bdata_final.drop(cat,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bdata_dr.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>TRAIN TEST SPLIT</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing sklearn for train test split\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating training set of features\nX=bdata_final.drop(['y'],axis=1)\n# creating training set of output variable\ny=pd.DataFrame(bdata_final['y'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting the dataset into train and test for both input and output variable\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>STANDARDIZING TRAINING AND TESTING SET</h4>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing the Standard Scaler from sklearn\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\ny_train = y_train.values.ravel()\ny_test = y_test.values.ravel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BALANCING THE DATASET**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing imblearn for Synthetic Minority Over Sampling Technique\n# NOTE : SMOTE technique needs the dataset to be numpy array\n\n# from imblearn.over_sampling import SMOTE\n# sm = SMOTE(sampling_strategy='auto', k_neighbors=1, random_state=0)\n# X_res, y_res = sm.fit_resample(X_train, y_train)\n# import numpy as np\n# np.savetxt('xres.txt', X_res, fmt='%f')\n# np.savetxt('yres.txt', y_res, fmt='%d')\n\n# SMOTE applied dataset\nimport numpy as np\nX_res = np.loadtxt('../input/smotedata/xres.txt', dtype=float)\ny_res = np.loadtxt('../input/smotedata/yres.txt', dtype=int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('No 0f 0 case :',y_res[y_res==0].shape[0])\nprint('No of 1 case :',y_res[y_res==1].shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h4>FITTING MODEL</h4>"},{"metadata":{},"cell_type":"markdown","source":"__Random Forest Classifier__"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# Create the model with 100 trees\nmodelrf = RandomForestClassifier(n_estimators=100, \n                               bootstrap = True,\n                               max_features = 'sqrt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit on training data\nmodelrf.fit(X_res, y_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the testing set results\ny_pred = modelrf.predict(X_test)\ny_pred = (y_pred > 0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import LinearSVC\nmodelsv = LinearSVC(max_iter=100,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelsv.fit(X_res, y_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the testing set results\ny_pred = modelsv.predict(X_test)\ny_pred = (y_pred > 0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**K-Nearest Neighbour Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nmodelkn = KNeighborsClassifier(n_neighbors=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelkn.fit(X_res, y_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the testing set results\ny_pred = modelkn.predict(X_test)\ny_pred = (y_pred > 0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodellr = LogisticRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modellr.fit(X_res, y_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the testing set results\ny_pred = modellr.predict(X_test)\ny_pred = (y_pred > 0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Naive Bayes Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nmodelnb = GaussianNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelnb.fit(X_res, y_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting the testing set results\ny_pred = modelnb.predict(X_test)\ny_pred = (y_pred > 0.50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing confusion matrix and roc_auc_score from sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\n\n# importing seaborn for plotting the heatmap\nimport seaborn as sn\n\ncm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\ndf_cm = pd.DataFrame(cm, index = ('no', 'yes'), columns = ('predicted no',\n                                                           'predicted yes'))\nplt.figure(figsize = (5,4))\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nsn.set(font_scale=1.4)\nsn.heatmap(df_cm, annot=True, fmt='g')\nplt.show()\nprint(\"Test Data Accuracy: %0.4f\" % roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing roc curve and metrics from sklearn\nfrom sklearn.metrics import roc_curve\nimport sklearn.metrics as metrics\n\nfpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\nroc_auc=roc_auc_score(y_test, y_pred)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.001, 1])\nplt.ylim([0, 1.001])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python (venv)","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":1}